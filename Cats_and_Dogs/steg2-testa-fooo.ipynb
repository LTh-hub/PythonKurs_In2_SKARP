{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e02860-38b8-423e-9fb7-f59bd0baa764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Convolutional Neural Networks - Deep Learning basics with Python, TensorFlow and Keras p.3\n",
    "#\n",
    "# Här under Steg 2 testas funktion med CNN modell på tränings-bilder med katter och hundar\n",
    "# Tränings-bilder samt Test-bilder togs fram under Steg 1\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9c6688b-b62e-4ff2-98cc-e92db765d91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\LTH_data\\photo\\PythUtbPic\\SKARP\\X_train.pickle\n",
      "C:\\LTH_data\\photo\\PythUtbPic\\SKARP\\y_train.pickle\n",
      "Epoch 1/10\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 0.6290 - loss: 0.7942 - val_accuracy: 0.8143 - val_loss: 0.4062\n",
      "Epoch 2/10\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 113ms/step - accuracy: 0.8272 - loss: 0.3941 - val_accuracy: 0.8524 - val_loss: 0.3545\n",
      "Epoch 3/10\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 119ms/step - accuracy: 0.8465 - loss: 0.3501 - val_accuracy: 0.8472 - val_loss: 0.3407\n",
      "Epoch 4/10\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 114ms/step - accuracy: 0.8696 - loss: 0.2990 - val_accuracy: 0.8684 - val_loss: 0.3248\n",
      "Epoch 5/10\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 112ms/step - accuracy: 0.8830 - loss: 0.2811 - val_accuracy: 0.8468 - val_loss: 0.3280\n",
      "Epoch 6/10\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 114ms/step - accuracy: 0.8977 - loss: 0.2395 - val_accuracy: 0.8610 - val_loss: 0.3321\n",
      "Epoch 7/10\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 113ms/step - accuracy: 0.9139 - loss: 0.2109 - val_accuracy: 0.8589 - val_loss: 0.3585\n",
      "Epoch 8/10\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 112ms/step - accuracy: 0.9242 - loss: 0.1805 - val_accuracy: 0.8593 - val_loss: 0.3590\n",
      "Epoch 9/10\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - accuracy: 0.9304 - loss: 0.1663 - val_accuracy: 0.8584 - val_loss: 0.3600\n",
      "Epoch 10/10\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 113ms/step - accuracy: 0.9430 - loss: 0.1380 - val_accuracy: 0.8511 - val_loss: 0.4060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19d25470530>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "DATADIR = \"C:\\\\LTH_data\\\\photo\\\\PythUtbPic\\\\SKARP\\\\\"     # path till katalog med djurbilder\n",
    "DATADIR_MOD = DATADIR                                    # path till sparad modell\n",
    "\n",
    "TxT_INP_fileN = DATADIR_MOD + \"X_train.pickle\"           # Filnamn indata\n",
    "TxT_OUT_fileN = DATADIR_MOD + \"y_train.pickle\"           # Filnamn utdata\n",
    "\n",
    "print(TxT_INP_fileN)\n",
    "print(TxT_OUT_fileN)\n",
    "\n",
    "X_train = pickle.load(open(TxT_INP_fileN,\"rb\"))          # Läs Indata - bildmatrl\n",
    "y_train = pickle.load(open(TxT_OUT_fileN,\"rb\"))          # Läs Utdata - (0/1) (katt/hund)\n",
    "\n",
    "X_train = X_train/255.0                                  # Normera gråskallenivå, (0,255) transformeras till (0,1), utan medlevärdesförskjutning\n",
    "\n",
    "model = Sequential()                                     # Linear stack med lager skickas in på variabel model\n",
    "\n",
    "                                                         # 'add' lägger till en lager instans på toppen av lager stacken\n",
    "model.add(Conv2D(64, (3,3), input_shape = X_train.shape[1:]))  # 1:a lagrets faltningskärna, faltas med lagrets indata\n",
    "model.add(Activation(\"relu\"))                            # aktiverings-fooo för den likriktade linjära enheten\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))                 # Reduces spatial dimensions by factor of 2\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))                     # 2:a lagrets Convolution NN block\n",
    "model.add(Activation(\"relu\"))                    # 2:a lagrets aktiverings-fooo\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))         # 2:a lagrets spatsiala dimensionsreducerare\n",
    "\n",
    "model.add(Flatten())                             # Konvertera 3D maps till en 1D feature vector\n",
    "model.add(Dense(64))                             # Regular densely-connected NN layer. positive integer, dimensionality of the output space.\n",
    "\n",
    "model.add(Dense(1))                              # 3:e,    output-lager \n",
    "model.add(Activation('sigmoid'))                 # sigmoid aktiverings-fooo\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",        # Konfigurerar modellen inför träning\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.3)    # Träna modellen för ett fixt antal epochs (iterationer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cadd9c4c-0174-4c47-bf1f-e583dcd46fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (7700, 75, 75, 1)       X_train.size = 43312500       len(X_train) = 7700          \n",
      "y_train.shape = (7700, 1)                 y_train.size = 7700           len(y_train) = 7700  \n"
     ]
    }
   ],
   "source": [
    "print(f\"{X_train.shape = }       {X_train.size = }       {len(X_train) = }          \")\n",
    "print(f\"{y_train.shape = }                 {y_train.size = }           {len(y_train) = }  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ef2fda8-5c48-48ab-bdef-b4d18a3ec99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(X_train) = <class 'numpy.ndarray'>       type(y_train) = <class 'numpy.ndarray'>    \n"
     ]
    }
   ],
   "source": [
    "print(f\"{type(X_train) = }       {type(y_train) = }    \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4042716-129e-4f61-9c51-3cd015f37bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9958edc0-0a40-4d35-b81f-c2735057dd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Sequential name=sequential_2, built=True>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1dc1a-f258-4359-ba1a-261c13b744e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132b8fc-145d-4d2b-b476-f3b0a634ed19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fda9fd-cf7f-4766-aa53-a175297fecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# SLUTSATS :: Utifrån fullskaleträning med hela gruppen av tränings-bilder, 3500 katter och 4200 hundar, är det en helhet som tycks fungera\n",
    "#             1. Har Importerat stor grupp bilder\n",
    "#             2. Tvättat datat, minskat pixelantal, normerad gråskalenivå\n",
    "#             3. Delat upp ursprungs datat (80/20) träning / testning \n",
    "#                - Här också uppdelning i \"model.fit(\" som (70/30) träning / validering\n",
    "#                - Alltså tränings-gruppen á 7700 bilder gruperas som (5390/2310) träning / validering\n",
    "#             4. Skapat modell; Secventiell Convolution Neutral Network model - CNN\n",
    "#             5. Försök att tränar modellen fungerar\n",
    "#             6. Nästa steg:\n",
    "#                - Utvärdera och testa\n",
    "#                - noggrannhet (accruracy), precision (precision), avvikelse (loss)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287db21c-c259-46ca-be3a-e2ae5a7d8470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3099ca5-e212-4340-91b3-05e16479fd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba9a00-c1b0-4414-a2a4-505979839787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f609811-5958-4958-8324-88e33cc88507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042dda62-4795-4145-b7ac-2e408bf780cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06864e56-42d8-438d-8de7-91c3448af635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
